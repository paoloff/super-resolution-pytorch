{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get necessary Python packages\n",
    "\n",
    "# Clone repos\n",
    "!git clone https://github.com/paoloff/super-resolution-packages.git\n",
    "\n",
    "# Install Python packages for Scene Text Telescope and ESPCN-PyTorch\n",
    "!pip install requirements.txt\n",
    "\n",
    "# Install Python packages for Super-image\n",
    "!pip install super-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "from IPython import embed\n",
    "from easydict import EasyDict\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "import torchvision\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from IPython import embed\n",
    "from datetime import datetime\n",
    "from time import gmtime, strftime\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open all images inside \"data\" folder and store them as np arrays\n",
    "input_folder = \"slide-labels-old\"\n",
    "output_folder = \"slide-labels-new\"\n",
    "\n",
    "img_paths = [os.path.join(input_folder, img) for img in os.listdir(data_path)]\n",
    "\n",
    "img_array = []\n",
    "raw_imgs = []\n",
    "\n",
    "for img in img_paths:\n",
    "    raw = Image.open(img)\n",
    "    raw_imgs.append(raw)\n",
    "    img_array.append(np.array(raw))\n",
    "\n",
    "N_images = len(img_array)\n",
    "\n",
    "# Define output folders for each model\n",
    "output_folders = {}\n",
    "output_folders[\"stt\"] = os.path.join(output_folder, \"SceneTextTelescope_out\")\n",
    "output_folders[\"espcn\"] = os.path.join(output_folder,\"ESPCN_out\")\n",
    "output_folders[\"superimage\"] = os.path.join(output_folder,\"SuperImage_out\")\n",
    "\n",
    "for folder_name in output_folders.values():\n",
    "    try: os.mkdir(folder_name)\n",
    "    except: continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "\n",
    "### Quick links to the models\n",
    "\n",
    "\n",
    "1. [ESPCN](#espcn)\n",
    "\n",
    "2. [Super-image](#si)\n",
    "\n",
    "3. [Scene text telescope](#stt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='espcn'></a>\n",
    "### ESPCN\n",
    "\n",
    "Reference: https://github.com/Lornatang/ESPCN-PyTorch\n",
    "\n",
    "[Back to quick links](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paolo\\OneDrive\\Documents\\Upwork\\PANDA\\Text resolution enhancement\\Github\\ESPCN-PyTorch\n",
      "c:\\Users\\paolo\\OneDrive\\Documents\\Upwork\\PANDA\\Text resolution enhancement\\Github\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Clear modules\n",
    "try: \n",
    "    del sys.modules[\"utils\"]\n",
    "except:pass\n",
    "\n",
    "try:\n",
    "    del sys.modules[\"model\"]\n",
    "except: pass\n",
    "\n",
    "# Import inference module of ESPCN\n",
    "%cd ESPCN-PyTorch\n",
    "from inference import *\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this cell is to define arguments to main function\n",
    "\n",
    "# The parser will do that, can leave the default parameters they are\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Model architecture name, can leave as it is\n",
    "parser.add_argument(\"--model_arch_name\",\n",
    "                    type=str,\n",
    "                    default=\"espcn_x4\")\n",
    "\n",
    "# Upscale factor, can leave as it is\n",
    "parser.add_argument(\"--upscale_factor\",\n",
    "                    type=int,\n",
    "                    default=4)\n",
    "\n",
    "# List with the paths of images, can leave as it is if images are in the /data/ folder\n",
    "parser.add_argument(\"--inputs_paths\",\n",
    "                    type=str,\n",
    "                    default=img_paths,\n",
    "                    )\n",
    "\n",
    "# Name of output folder,  can leave as default: a folder named espcn_out inside /data/ folder\n",
    "parser.add_argument(\"--output_folder\",\n",
    "                    type=str,\n",
    "                    default=output_folders[\"espcn\"],\n",
    "                    )\n",
    "\n",
    "# Model weights path, can leave as default: ESPCN_x4-T91-64bf5ee4.pth.tar inside the /models/ folder\n",
    "parser.add_argument(\"--model_weights_path\",\n",
    "                    type=str,\n",
    "                    default=\"models/ESPCN_x4-T91-64bf5ee4.pth.tar\",\n",
    "                    )\n",
    "\n",
    "# Device type, default is GPU (cuda)\n",
    "parser.add_argument(\"--device_type\",\n",
    "                    type=str,\n",
    "                    default=\"cuda\",\n",
    "                    choices=[\"cpu\", \"cuda\"])\n",
    "\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build `espcn_x4` model successfully.\n",
      "Load `espcn_x4` model weights `c:\\Users\\paolo\\OneDrive\\Documents\\Upwork\\PANDA\\Text resolution enhancement\\Github\\models\\ESPCN_x4-T91-64bf5ee4.pth.tar` successfully.\n",
      "SR image save to `data\\ESPCN_out\\+_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\0_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\6_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\8_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\alcohol_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\BOX_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\GARAGE_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\GREEN_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\I_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\img_001_SRF_4_LR_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\img_002_SRF_4_LR_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\img_003_SRF_4_LR_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\img_004_SRF_4_LR_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\img_005_SRF_4_LR_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\in_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\Made_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\obstructing_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\OVERNIGHT_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\Pieces_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\Pistachios_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\PM_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\POLICE_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\PROSCIUTTO_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\SATINE_ESPCN_out.png`\n",
      "SR image save to `data\\ESPCN_out\\YOU!_ESPCN_out.png`\n"
     ]
    }
   ],
   "source": [
    "# Call main function\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='si'></a>\n",
    "\n",
    "### Super-image\n",
    "\n",
    "Reference: https://github.com/eugenesiow/super-image?tab=readme-ov-file\n",
    "\n",
    "[Back to quick links](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paolo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:659: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/eugenesiow/drln-bam/resolve/main/pytorch_model_4x.pt\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# From the catalogue of models inside the super-image package, I chose the one called dlrn-bam since it has the best overall performance\n",
    "from super_image import DrlnModel, ImageLoader\n",
    "\n",
    "model_si = DrlnModel.from_pretrained('eugenesiow/drln-bam', scale=4).to(\"cuda\")\n",
    "output_folder = output_folders[\"superimage\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paolo\\anaconda3\\Lib\\site-packages\\super_image\\data\\loader.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  return torch.as_tensor([lr])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/25 images converted by Super-Image model.\n",
      "5/25 images converted by Super-Image model.\n",
      "10/25 images converted by Super-Image model.\n",
      "15/25 images converted by Super-Image model.\n",
      "20/25 images converted by Super-Image model.\n"
     ]
    }
   ],
   "source": [
    "# Apply model to each image and store results in a list\n",
    "outs = []\n",
    "\n",
    "# This may take 2-3 minutes\n",
    "for i, img in enumerate(raw_imgs):\n",
    "    inputs = ImageLoader.load_image(img).to(\"cuda\")\n",
    "    outs.append(model_si(inputs).to(\"cpu\"))\n",
    "    if i%5 == 0:\n",
    "        print(f\"{i}/{N_images} images converted by Super-Image model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all processed images to the output folder\n",
    "for out, input_path in zip(outs,img_paths):\n",
    "    head, tail = os.path.split(input_path)\n",
    "    output_head = os.path.join(head, output_folder)\n",
    "    output_path = os.path.join(output_head, tail.split(\".\")[0]+\"_SuperImage_out.png\")\n",
    "    ImageLoader.save_image(out, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stt'></a>\n",
    "### Scene text telescope\n",
    "\n",
    "Reference: https://github.com/FudanVI/FudanOCR/tree/main/scene-text-telescope\n",
    "\n",
    "[Back to quick links](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paolo\\OneDrive\\Documents\\Upwork\\PANDA\\Text resolution enhancement\\Github\\scene-text-telescope\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Clear modules\n",
    "try: \n",
    "    del sys.modules[\"utils\"]\n",
    "except:pass\n",
    "\n",
    "try:\n",
    "    del sys.modules[\"model\"]\n",
    "except: pass\n",
    "\n",
    "# Import all the necessary STT modules\n",
    "%cd scene-text-telescope\n",
    "from interfaces import base\n",
    "from utils import utils_moran\n",
    "from interfaces.super_resolution import TextSR\n",
    "from utils.meters import AverageMeter\n",
    "from utils.metrics import get_str_list, Accuracy\n",
    "from utils import util, ssim_psnr\n",
    "from utils.util import str_filt\n",
    "\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this cell is to define arguments to main function\n",
    "\n",
    "# The parser will do that, can leave the default parameters they are\n",
    "parser = argparse.ArgumentParser(description='')\n",
    "parser.add_argument('--arch', default='tbsrn', choices=['tbsrn', 'tsrn', 'bicubic', 'srcnn', 'vdsr', 'srres', 'esrgan', 'rdn',\n",
    "                                                        'edsr', 'lapsrn'])\n",
    "parser.add_argument('--text_focus', action='store_true')\n",
    "parser.add_argument('--exp_name', required=False, help='Type your experiment name')\n",
    "parser.add_argument('--test', action='store_true', default=False)\n",
    "parser.add_argument('--test_data_dir', type=str, default='./dataset/mydata/test')\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='')\n",
    "parser.add_argument('--resume', type=str, default='', help='')\n",
    "parser.add_argument('--rec', default='crnn', choices=['crnn'])\n",
    "parser.add_argument('--STN', action='store_true', default=True, help='')\n",
    "parser.add_argument('--syn', action='store_true', default=False, help='use synthetic LR')\n",
    "parser.add_argument('--mixed', action='store_true', default=False, help='mix synthetic with real LR')\n",
    "parser.add_argument('--mask', action='store_true', default=False, help='')\n",
    "parser.add_argument('--hd_u', type=int, default=32, help='')\n",
    "parser.add_argument('--srb', type=int, default=5, help='')\n",
    "parser.add_argument('--demo', action='store_true', default=False)\n",
    "parser.add_argument('--demo_dir', type=str, default='./demo')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# There are additional configurations needed by the model which are located inside the config/super_resolution.yaml file, no need to change anything\n",
    "config_path = os.path.join('config', 'super_resolution.yaml')\n",
    "config = yaml.load(open(config_path, 'r'), Loader=yaml.Loader)\n",
    "config = EasyDict(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean the old checkpoint None\n",
      "Namespace(arch='tbsrn', text_focus=False, exp_name=None, test=False, test_data_dir='./dataset/mydata/test', batch_size=128, resume='', rec='crnn', STN=True, syn=False, mixed=False, mask=False, hd_u=32, srb=5, demo=False, demo_dir='./demo')\n",
      "Total Parameters 3210335\n",
      "c:\\Users\\paolo\\OneDrive\\Documents\\Upwork\\PANDA\\Text resolution enhancement\\Github\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model and importing the weights from /model/stt_pre_trained_weights.pth\n",
    "\n",
    "Mission = TextSR(config, args)\n",
    "model_dict = Mission.generator_init()\n",
    "model, image_crit = model_dict['model'], model_dict['crit']\n",
    "%cd ..\n",
    "weights = torch.load(\"models/stt_pre_trained_weights.pth\")\n",
    "model.load_state_dict(weights['state_dict_G'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-size the images into 3x16x64 tensors (necessary step for STT)\n",
    "\n",
    "resized_imgs = []\n",
    "for img in img_array:\n",
    "    resized_imgs.append(to_tensor(to_pil(cv2.resize(img, (64,16), interpolation=cv2.INTER_CUBIC))))\n",
    "\n",
    "resized_imgs_tensor = torch.stack(resized_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to enhance each image and saving to output folder\n",
    "\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# We do the computations on the GPU to speed them up. However, they can be done in cpu also\n",
    "with torch.no_grad():\n",
    "    outs_torch = model(resized_imgs_tensor.to(\"cuda\")).to(\"cpu\")\n",
    "\n",
    "outs = []\n",
    "for out in outs_torch:\n",
    "    outs.append(to_pil(out))\n",
    "\n",
    "output_folder = output_folders[\"stt\"]\n",
    "\n",
    "# Save all processed images to the output folder\n",
    "for out, input_path in zip(outs, img_paths):\n",
    "    head, tail = os.path.split(input_path)\n",
    "    output_head = os.path.join(head, output_folder)\n",
    "    output_path = os.path.join(output_head, tail.split(\".\")[0]+\"_SceneTextTelescope_out.png\")\n",
    "    out.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
